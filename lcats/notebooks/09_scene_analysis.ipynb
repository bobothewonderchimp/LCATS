{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b08a7f1",
   "metadata": {},
   "source": [
    "# Scene Extraction from Long Narratives with LLMs\n",
    "\n",
    "Originally from ChatGPT, this notebook explores how to extract narrative scenes from\n",
    "long stories using chunked input and OpenAI's GPT models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc52d9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbd180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1baf0",
   "metadata": {},
   "source": [
    "Third-party modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf3d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from openai import OpenAI\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1f48d",
   "metadata": {},
   "source": [
    "Add imports from within the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ce5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to the path so we can import modules from the parent directory.\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from lcats import stories\n",
    "from lcats import utils\n",
    "from lcats.datasets import torchdata\n",
    "from lcats.gatherers import extractors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d5eb52",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db985b9",
   "metadata": {},
   "source": [
    "### Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the following code is run from lcats/notebooks in VSCode and the data is in lcats/data ...\n",
    "CURRENT_PATH = os.path.abspath(os.curdir)  # This is where the notebook is executing.\n",
    "PROJECT_ROOT = os.path.dirname(CURRENT_PATH)   # This should be the root of the project.\n",
    "DEV_CORPUS = os.path.abspath(os.path.join(PROJECT_ROOT, 'data'))  # Local copy of the data.\n",
    "DEV_OUTPUT = os.path.abspath(os.path.join(PROJECT_ROOT, 'output'))  # Local copy of the data.\n",
    "GIT_CORPUS = os.path.abspath(os.path.join(PROJECT_ROOT, '../corpora'))  # Data in the git repo.\n",
    "OPENIA_API_KEYS_ENV = os.path.abspath(os.path.join(PROJECT_ROOT, '../.secrets/openai_api_keys.env'))  # Local OpenAI API key.\n",
    "\n",
    "def check_path(path, description):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Found {description} at: {path}\")\n",
    "    else:\n",
    "        print(f\"Missing {description} from: {path}\")\n",
    "\n",
    "check_path(DEV_CORPUS, \"DEV_CORPUS\")\n",
    "check_path(DEV_OUTPUT, \"DEV_OUTPUT\")\n",
    "check_path(GIT_CORPUS, \"GIT_CORPUS\")\n",
    "check_path(OPENIA_API_KEYS_ENV, \"OPENIA_API_KEYS_ENV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e3676",
   "metadata": {},
   "source": [
    "## OpenAI Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af164f31",
   "metadata": {},
   "source": [
    "Get the OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv(OPENIA_API_KEYS_ENV)\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba5af80",
   "metadata": {},
   "source": [
    "Verify that we can get a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "print(f\"Loaded OpenAI client: {client} with version: {client._version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd89ed6",
   "metadata": {},
   "source": [
    "Verify the API is working. This week. And that you have credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f083965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Write a one-sentence bedtime story about a starship captain visiting a planet.\"\n",
    ")\n",
    "\n",
    "print(f\"Story generated on: {date.today()}:\")\n",
    "utils.pprint(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa66921c",
   "metadata": {},
   "source": [
    "## Story Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21172e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the modules to ensure we have the latest code, if doing active development.\n",
    "if False: \n",
    "    from importlib import reload\n",
    "    reload(stories)\n",
    "    reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If run from within a notebook, the corpora root is two paths up from the notebook's location.\n",
    "CORPORA_ROOT = GIT_CORPUS  # Checked-in corpora\n",
    "# CORPORA_ROOT = DEV_CORPUS  # Command line working corpora\n",
    "\n",
    "# Now load the corpora\n",
    "corpora = stories.Corpora(CORPORA_ROOT)\n",
    "\n",
    "print(\"Loaded corpora:\")\n",
    "print(f\" - root: {corpora.corpora_root}\")\n",
    "print(f\" - corpora: {len(corpora.corpora)}\")\n",
    "print(f\" - stories: {len(corpora.stories)}\")\n",
    "print()\n",
    "print(f\"Example story: corpora.stories[0]:\")\n",
    "print(corpora.stories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac9f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_story = corpora.stories[0]\n",
    "print(f\"Story type: {type(example_story)} with a body of {len(example_story.body)} characters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0112b",
   "metadata": {},
   "source": [
    "## Text Chunking Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707089d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text: str, model: str = \"gpt-3.5-turbo\") -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ec367",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = []\n",
    "for story in corpora.stories:\n",
    "    token_count = count_tokens(story.body)\n",
    "    token_counts.append({\n",
    "        'name': story.name,\n",
    "        'body_length': len(story.body),\n",
    "        'token_count': token_count\n",
    "    })\n",
    "sorted_token_counts = sorted(token_counts, key=lambda x: x['token_count'], reverse=True)\n",
    "token_counts_df = pd.DataFrame(sorted_token_counts)\n",
    "print(\"Token counts for all stories:\")\n",
    "print(\"tokens\\tlength\\tname\")\n",
    "print(\"------\\t------\\t----\")\n",
    "for index, row in token_counts_df.iterrows():\n",
    "    print(f\"{row['token_count']}\\t{row['body_length']}\\t{row['name']}\")\n",
    "\n",
    "token_counts_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunk_text(text: str, max_tokens: int = 800, overlap: int = 100) -> List[Dict]:\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        chunk = words[start:start+max_tokens]\n",
    "        chunk_text = \" \".join(chunk)\n",
    "        chunks.append({\n",
    "            \"chunk_index\": len(chunks),\n",
    "            \"start_word\": start,\n",
    "            \"end_word\": start+len(chunk),\n",
    "            \"text\": chunk_text\n",
    "        })\n",
    "        start += max_tokens - overlap\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49407b4b",
   "metadata": {},
   "source": [
    "## 3. Prompt Builder and LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebf9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_prompt(chunk: str) -> List[Dict]:\n",
    "    return [{\n",
    "        \"role\": \"system\", \n",
    "        \"content\": \"You are a literary analyst trained to identify narrative scenes.\"\n",
    "    }, {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": f\"Analyze the following text and identify narrative scenes or interstitial elements. For each scene, describe the time, place, characters, and type (dramatic, sequel, interstitial). Return output in JSON with a top-level key 'events':\\n\\n{chunk}\"\n",
    "    }]\n",
    "\n",
    "def call_openai_api(messages: List[Dict], model=\"gpt-3.5-turbo\") -> str:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.2\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee19dfb",
   "metadata": {},
   "source": [
    "## 4. Parse LLM Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4391a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def try_parse_json(output: str):\n",
    "    try:\n",
    "        return json.loads(output)\n",
    "    except json.JSONDecodeError:\n",
    "        start = output.find(\"{\")\n",
    "        end = output.rfind(\"}\") + 1\n",
    "        try:\n",
    "            return json.loads(output[start:end])\n",
    "        except:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83159cf6",
   "metadata": {},
   "source": [
    "## 5. Full Scene Extraction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aece9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_scenes_from_text(text: str) -> List[Dict]:\n",
    "    chunks = chunk_text(text)\n",
    "    all_scenes = []\n",
    "    for chunk in chunks:\n",
    "        messages = build_prompt(chunk[\"text\"])\n",
    "        response = call_openai_api(messages)\n",
    "        parsed = try_parse_json(response)\n",
    "        if parsed and \"events\" in parsed:\n",
    "            for event in parsed[\"events\"]:\n",
    "                event[\"chunk_index\"] = chunk[\"chunk_index\"]\n",
    "                all_scenes.append(event)\n",
    "    return all_scenes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3722e6d1",
   "metadata": {},
   "source": [
    "## 6. Run Extraction on a Sample Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff7ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_text = \"\"\"\n",
    "Once upon a time in a village nestled in the mountains, a girl named Lila dreamed of touching the stars...\n",
    "\"\"\"\n",
    "\n",
    "scenes = extract_scenes_from_text(sample_text)\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(scenes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCATS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
