{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with Text Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable imports within the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to the path so we can import modules from the parent directory.\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import lcats.constants as constants\n",
    "import lcats.utils as utils\n",
    "import lcats.gatherers.downloaders as downloaders\n",
    "import lcats.gatherers.extractors as extractors\n",
    "import lcats.gatherers.lovecraft.gutenberg as lovecraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:  # Code to reload modules if we make local code changes, off by default.\n",
    "    from importlib import reload\n",
    "    reload(downloaders)\n",
    "    reload(lovecraft)\n",
    "    reload(extractors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the Lovecraft Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaders.get_page_encoding('https://www.gutenberg.org/cache/epub/68283/pg68283-images.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lovecraft.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lovecraft_files = lovecraft.THE_LOVECRAFT_FILES\n",
    "len(lovecraft_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lovecraft_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Broken URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloads = []\n",
    "for story in lovecraft_files:\n",
    "    print(\"Story:\", story)\n",
    "    url = lovecraft_files[story] \n",
    "    print(\" - url:\", url)\n",
    "    contents = downloaders.load_page(url)\n",
    "    print(\" - contents:\", contents[:100])\n",
    "    soup = BeautifulSoup(contents, \"lxml\")\n",
    "    if soup.title:\n",
    "        print(\" - title:\", soup.title.string)\n",
    "    else:\n",
    "        print(\" - title: None\")\n",
    "    print()\n",
    "    downloads.append((story, url, contents, soup))\n",
    "\n",
    "print(len(downloads))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Gathering for Known URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_title = 'the_call_of_cthulhu'\n",
    "story_url = lovecraft_files[story_title]\n",
    "\n",
    "response = requests.get(story_url)\n",
    "print(f\"Detected encoding: {response.encoding}\")\n",
    "story_encoding = response.encoding\n",
    "\n",
    "story_content = downloaders.load_page(story_url, encoding=story_encoding)\n",
    "story_callback = lovecraft.create_download_callback(\n",
    "    story_name=story_title,\n",
    "    url=story_url,\n",
    "    start_heading_text=story_title,\n",
    "    description=story_title\n",
    ")\n",
    "gatherer = downloaders.DataGatherer(\n",
    "    \"lovecraft\",\n",
    "    description=\"H.P. Lovecraft stories\",\n",
    "    license=\"Public Domain\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gatherer.download(story_title, story_url, story_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_SEPARATOR = 'pg-start-separator'\n",
    "END_SEPARATOR = 'pg-end-separator'\n",
    "CONTENT_TAGS = ['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']\n",
    "\n",
    "def extract_tags_between_ids(soup, start_id, end_id, content_tags):\n",
    "    start_tag = soup.find(id=start_id)\n",
    "    end_tag = soup.find(id=end_id)\n",
    "    current_tag = start_tag.find_next()\n",
    "    matching_tags = []\n",
    "    while current_tag and current_tag != end_tag:\n",
    "        if current_tag.name in content_tags:\n",
    "            matching_tags.append(current_tag)\n",
    "        current_tag = current_tag.find_next()\n",
    "    \n",
    "    return matching_tags\n",
    "\n",
    "\n",
    "def extract_text_from_tags(tags, separator=\"\\n\\n\"):\n",
    "    collected_text = []\n",
    "    for tag in tags:\n",
    "        tag_text = tag.get_text(\" \", strip=True)\n",
    "        if tag_text:\n",
    "            collected_text.append(tag_text)\n",
    "    \n",
    "    return separator.join(collected_text)\n",
    "\n",
    "\n",
    "# Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(story_content, 'lxml')\n",
    "matching_tags = extract_tags_between_ids(soup, START_SEPARATOR, END_SEPARATOR, CONTENT_TAGS)\n",
    "matching_text = extract_text_from_tags(matching_tags)\n",
    "print()\n",
    "print(len(matching_tags), len(matching_text))\n",
    "print()\n",
    "print(matching_tags[:5])\n",
    "print()\n",
    "print(utils.sm(matching_text, 1000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matching_text[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tag = random.choice(matching_tags)\n",
    "print(example_tag.name, type(example_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT = [1, 2]\n",
    "\n",
    "def deefault():\n",
    "    thing = DEFAULT\n",
    "    thing.append(3)\n",
    "    return thing\n",
    "\n",
    "deefault(), DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codecs.lookup('garbage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCATS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
